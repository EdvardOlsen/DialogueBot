{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KZSQc1SyUrq"
      },
      "source": [
        "## Tacotron 2 inference code \n",
        "Edit the variables **checkpoint_path** and **text** to match yours and run the entire code to generate plots of mel outputs, alignments and audio synthesis from the generated mel-spectrogram using Griffin-Lim."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrvfFx6GyUr2"
      },
      "source": [
        "#### Import libraries and setup matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzOl0f41Bm_X"
      },
      "source": [
        "!git clone https://github.com/EdvardOlsen/DialogueBot.git\n",
        "!cp -r DialogueBot/* .\n",
        "!chmod 777 setup.sh \n",
        "!./setup.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRtbNLM7yUr3"
      },
      "source": [
        "from denoiser import Denoiser\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import IPython.display as ipd\n",
        "\n",
        "import sys\n",
        "sys.path.append('waveglow/')\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from hparams import create_hparams\n",
        "from model import Tacotron2\n",
        "from layers import TacotronSTFT, STFT\n",
        "from audio_processing import griffin_lim\n",
        "from train import load_model\n",
        "from text import text_to_sequence\n",
        "import speech_recognition as sr\n",
        "import transformers\n",
        "import IPython\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQuWCJTFyUr4"
      },
      "source": [
        "def plot_data(data, figsize=(16, 4)):\n",
        "    fig, axes = plt.subplots(1, len(data), figsize=figsize)\n",
        "    for i in range(len(data)):\n",
        "        axes[i].imshow(data[i], aspect='auto', origin='bottom', \n",
        "                       interpolation='none')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3mPDEjAyUr4"
      },
      "source": [
        "#### Setup hparams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMZUbcbYyUr5"
      },
      "source": [
        "hparams = create_hparams()\n",
        "hparams.sampling_rate = 22050"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtwJO_gEyUr5"
      },
      "source": [
        "#### Load model from checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_-ReXaB4oE3"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6Ib0L2IyUr5"
      },
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/tacotron/...\"\n",
        "model = load_model(hparams)\n",
        "model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n",
        "_ = model.cuda().eval().half()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpxUh96nyUr6"
      },
      "source": [
        "#### Load WaveGlow for mel2audio synthesis and denoiser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiQdtC8myUr6"
      },
      "source": [
        "waveglow_path = '/content/drive/MyDrive/tacotron/...'\n",
        "waveglow = torch.load(waveglow_path)['model']\n",
        "waveglow.cuda().eval().half()\n",
        "for k in waveglow.convinv:\n",
        "    k.float()\n",
        "denoiser = Denoiser(waveglow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaaFZKGhyUr7"
      },
      "source": [
        "#### Prepare text input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB96RorSyUr7"
      },
      "source": [
        "import soundfile as sf\n",
        "text = \"Hi my name is DialogueBot I am happy to meet you.\"\n",
        "def generate_voice(text):\n",
        "  sequence = np.array(text_to_sequence(text, ['english_cleaners']))[None, :]\n",
        "  sequence = torch.autograd.Variable(\n",
        "      torch.from_numpy(sequence)).cuda().long()\n",
        "  mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
        "  with torch.no_grad():\n",
        "      audio = waveglow.infer(mel_outputs_postnet, sigma=0.666)\n",
        "  audio = denoiser(audio, strength=0.01)[:, 0]\n",
        "  audio = np.float32(audio[0].data.cpu().numpy())\n",
        "  sf.write('audio.wav', audio, samplerate = hparams.sampling_rate)\n",
        "  return 'audio.wav'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmnTWLJy657O"
      },
      "source": [
        "IPython.display.Audio('audio.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjcGuu7V1p9d"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "modelgpt = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-large\")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T3KWEoB1QK3"
      },
      "source": [
        "def recognise(audio_file):\n",
        "  with sr.AudioFile(audio_file) as source:\n",
        "    audio = r.record(source)  \n",
        "  return r.recognize_google(audio)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWVIj9tl1QzN"
      },
      "source": [
        "def generate_answer_text(text):\n",
        "  new_user_input_ids = tokenizer.encode(text + tokenizer.eos_token, return_tensors='pt')\n",
        "  answer_ids = modelgpt.generate(new_user_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
        "  return tokenizer.decode(answer_ids[:, new_user_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "\n",
        "generate_answer_text('hi how are you')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eIuNj074xv4"
      },
      "source": [
        "generate_answer_text('hehe')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUQ1oydA1Uc5"
      },
      "source": [
        "def generate_answer_audio(audiofile):\n",
        "  text = recognise(audiofile)\n",
        "  print(text)\n",
        "  return generate_answer_text(text)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUmmwR875DLF"
      },
      "source": [
        "def make_response(oggfile):\n",
        "  convert_to_wav(oggfile)\n",
        "  text_user = recognise('tmp.wav')\n",
        "  print(text_user)\n",
        "  text_answer = generate_answer_text(text_user)\n",
        "  wav = generate_voice(text_answer)\n",
        "  return convert_to_ogg(wav)\n",
        "\n",
        "make_response('new_file.ogg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTJ1MWrV022R"
      },
      "source": [
        "token=''\n",
        "import telebot\n",
        "from urllib.request import urlretrieve\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "i = 0\n",
        "r = sr.Recognizer()\n",
        "\n",
        "def convert_to_wav(filename):\n",
        "  data, sr = librosa.load(filename)\n",
        "  sf.write('tmp.wav', data, sr)\n",
        "  return 'tmp.wav'\n",
        "\n",
        "def convert_to_ogg(filename):\n",
        "  data, sr = librosa.load(filename)\n",
        "  sf.write('tmp.ogg', data, sr)\n",
        "  return 'tmp.ogg'\n",
        "\n",
        "def make_response(oggfile):\n",
        "  convert_to_wav(oggfile)\n",
        "  text_user = recognise('tmp.wav')\n",
        "  text_answer = generate_answer_text(text_user)\n",
        "  wav = generate_voice(text_answer)\n",
        "  return convert_to_ogg(wav)\n",
        "\n",
        "bot = telebot.TeleBot(token)\n",
        "@bot.message_handler(content_types=[\"audio\", \"text\", \"voice\"])\n",
        "def handle(message, i=10): \n",
        "    try:\n",
        "      file_info = bot.get_file(message.voice.file_id)\n",
        "      downloaded_file = bot.download_file(file_info.file_path)\n",
        "      with open('new_file.ogg', 'wb') as new_file:\n",
        "        new_file.write(downloaded_file)\n",
        "      new_name = convert_to_wav('new_file.ogg')\n",
        "      answer = make_response(new_name)\n",
        "      bot.send_audio(chat_id=message.chat.id, audio=open('audio.wav', 'rb'))\n",
        "\n",
        "    except ValueError:\n",
        "      bot.send_message(chat_id=message.chat.id, text='hehe')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsdofFUg3kIi"
      },
      "source": [
        "bot.polling()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}